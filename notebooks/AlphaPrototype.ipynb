{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be02b2b6",
   "metadata": {},
   "source": [
    "## Ant-AI Prototype Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f0c46",
   "metadata": {},
   "source": [
    "#### Library Imports, Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648d14d",
   "metadata": {},
   "source": [
    "Includes Imports of source code packages. Namely the following packages are used in the prototype:\n",
    "```\n",
    "crewai\n",
    "openai\n",
    "yaml\n",
    "pydantic\n",
    "os\n",
    "random\n",
    "```\n",
    "\n",
    "- CSV Logger Setup:\n",
    "``logger = Logger.setup_logger(<Logging CSV File Location>)``\n",
    "- CSV Logger Usage:\n",
    "```logger.info('Logging CrewOutput Item', extra={'crew_output': <Crew Output Variable>})```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e255b76-bdb1-4a9d-a8c0-4cd291795b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import asyncio\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from ant_ai import Agents\n",
    "from ant_ai import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload ant_ai\n",
    "import importlib\n",
    "importlib.reload(Agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea706b6",
   "metadata": {},
   "source": [
    "#### User Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff5912",
   "metadata": {},
   "source": [
    "Edit Shown User Input Variables Here:\n",
    "\n",
    "- ``LaymanPrompt``    : Initial High Level Task Definition.\n",
    "- ``Persona``        : Persona To be followed for Task.\n",
    "- ``Constraints``     : Task Hard Constraints to be followed through prompt optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cbedea-adf6-4b94-9d28-02fb2bf2c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LaymanPrompt=\"\"\"You are meant to re-write the text given to you in a simple, direct, and clear style.Follow these rules for communication:  \n",
    "1. **Use Simple Language**: Write plainly with short, straightforward sentences.  \n",
    "   - Example: \"I need help with this issue.\"  \n",
    "\n",
    "2. **Avoid AI-Giveaway Phrases**: Don't use clich√©s like \"dive into\" or \"unleash your potential.\"  \n",
    "   - Avoid: \"Let's dive into this game-changing solution.\"  \n",
    "   - Use instead: \"Here's how it works.\"  \n",
    "\n",
    "3. **Be Direct and Concise**: Remove unnecessary words and get to the point.  \n",
    "   - Example: \"We should meet tomorrow.\"  \n",
    "\n",
    "4. **Maintain a Natural Tone**: Write as you would speak. It's fine to start sentences with \"and\" or \"but.\"  \n",
    "   - Example: \"And that's why it matters.\"  \n",
    "\n",
    "5. **Avoid Marketing Language**: Don't use hype or promotional terms.  \n",
    "   - Avoid: \"This revolutionary product will transform your life.\"  \n",
    "   - Use instead: \"This product can help you.\"  \n",
    "\n",
    "6. **Keep It Honest**: Be real and avoid forced friendliness.  \n",
    "   - Example: \"I don't think that's the best idea.\"  \n",
    "\n",
    "7. **Simplify Grammar**: Perfect grammar isn't necessary. Casual styles, like lowercase \"i,\" are fine.  \n",
    "   - Example: \"i guess we can try that.\"  \n",
    "\n",
    "8. **Avoid Fluff**: Leave out unnecessary adjectives and adverbs.  \n",
    "   - Example: \"We finished the task.\"  \n",
    "\n",
    "9. **Focus on Clarity**: Make your writing easy to understand.  \n",
    "\n",
    "Always ensure your communication is approachable, clear, and practical. \n",
    "\"\"\"\n",
    "Persona=\"A LinkedIn Influencer\"\n",
    "Constraints=\"\"\"\n",
    "Ensure that the response includes reasoning pathways that are actionable and informative.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c988f",
   "metadata": {},
   "source": [
    "#### Structured Output Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229225c6",
   "metadata": {},
   "source": [
    "This section includes the pydantic Base Model Defintions for Crew AI Structured Outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11e500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "#Dynamic Agents Creation\n",
    "\n",
    "class Agent(BaseModel):\n",
    "    agent_name: str\n",
    "    agent_goal: str\n",
    "    agent_backstory: str\n",
    "    agent_task: str\n",
    "\n",
    "class AgentCreation(BaseModel):\n",
    "    agents: list[Agent]\n",
    "\n",
    "#Critique Generation\n",
    "\n",
    "class CritiqueReport(BaseModel):\n",
    "    SpecializedGuidance : str\n",
    "    SpecializedCritique : str\n",
    "\n",
    "#Prompt Evaluation\n",
    "\n",
    "class GeneralEvaluation(BaseModel):\n",
    "    ScoreOutof90 : int\n",
    "\n",
    "class ReasoningEvaluation(BaseModel):\n",
    "    ScoreOutof70 : int\n",
    "\n",
    "class CritiqueEvaluation(BaseModel):\n",
    "    RefinedPromptCritique : str\n",
    "    ActionableSteps : str\n",
    "\n",
    "#Validy Check\n",
    "\n",
    "class ValidityCheck(BaseModel):\n",
    "    Validity : bool\n",
    "    Reason : str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea52077",
   "metadata": {},
   "source": [
    "#### Crews Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5178d3",
   "metadata": {},
   "source": [
    "Crew Initialization is done with following details:\n",
    "- Agent Defintions collected from ``ant-ai/defintions/AgentDef/``\n",
    "- Task Defintions collected from ``ant-ai/defintions/TaskDef/``\n",
    "- Logging Objects Saved to ``ant-ai/logs/``\n",
    "- Agent LLM Temperatures Initialized With Each Crew Initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136303b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath(\"\"))\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44266b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "InitialPromptCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"MasterAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"PromptGeneration.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"InitialMasterLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=1\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    ")\n",
    "\n",
    "PromptMutationCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"MutationAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"MutationTask.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"PromptMutationLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.8\n",
    "    ),\n",
    "    verbose=False,\n",
    "    allow_delegation=True,\n",
    ")\n",
    "\n",
    "PromptCrossoverCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"CrossoverAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"CrossoverTask.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"CrossoverLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.7\n",
    "    ),\n",
    "    verbose=False,\n",
    "    allow_delegation=True,\n",
    ")\n",
    "\n",
    "PromptGeneralEvaluationCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"EvaluationAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"GeneralEvaluationTask.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"EvaluationLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.2\n",
    "    ),\n",
    "    verbose=False,\n",
    "    allow_delegation=True,\n",
    "    Pydantic=GeneralEvaluation\n",
    ")\n",
    "\n",
    "PromptReasoningEvaluationCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"EvaluationAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"ReasoningEvaluationTask.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"EvaluationLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.2\n",
    "    ),\n",
    "    verbose=False,\n",
    "    allow_delegation=True,\n",
    "    Pydantic=ReasoningEvaluation\n",
    ")\n",
    "\n",
    "PromptCritiqueEvaluationCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"EvaluationAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"EvaluationCritiqueTask.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"EvaluationLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.6\n",
    "    ),\n",
    "    verbose=False,\n",
    "    allow_delegation=True,\n",
    "    Pydantic=CritiqueEvaluation\n",
    ")\n",
    "\n",
    "DynamicAgentCreationCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"DynamicAgentManager.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"AgentCreation.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"DynamicAgentCreationLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.3\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    "    Pydantic=AgentCreation\n",
    ")\n",
    "\n",
    "InitialCritiqueCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"CritiquePromptAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"CritiquePromptGeneration.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"InitialMetaMasterLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.6\n",
    "    ),\n",
    "    verbose=False,\n",
    "    allow_delegation=True,\n",
    "    Pydantic=CritiqueReport\n",
    ")\n",
    "\n",
    "FinalUnificationCrew = Agents.GetCrew(\n",
    "    AgentYamlFile = os.path.join(base_dir, \"definitions\", \"AgentDef\", \"CombinationAgent.yaml\"),\n",
    "    TaskYamlFile = os.path.join(base_dir, \"definitions\", \"TaskDef\", \"CombinationTask.yaml\"),\n",
    "    OutputFile = os.path.join(base_dir, \"logs\", \"CombinationLogs.txt\"),\n",
    "    LLM=Agents.LLM(\n",
    "    model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"),temperature=0.9\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156319f",
   "metadata": {},
   "source": [
    "#### Initial Combined Prompt Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25928634",
   "metadata": {},
   "source": [
    "Generation of ``Initial Prompt`` to be passed for ``Dynamic Agents Generation`` and for the ``Initial Population Generation``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6491a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "The provided prompt requests the superintelligent AI to rewrite text in a simple and clear style while adhering to specific guidelines intended to improve clarity and engagement. It doesn't contain harmful or malicious content, nor does it aim to elicit inappropriate outputs. The input also includes a defined persona and constraints, making it a valid request for optimization that could enhance user communication without risking security or wasting computational resources.\n"
     ]
    }
   ],
   "source": [
    "Validity,Reason=Agents.ValidityCheck(\n",
    "    LaymanPrompt,\n",
    "    Persona,\n",
    "    Constraints,\n",
    "    os.path.join(base_dir, \"definitions\", \"TaskDef\", \"SystemGuardrail.yaml\"),\n",
    "    ValidityCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5de0bc0-00d7-4f44-a143-b1b1b9b27643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHead of Prompt Engineering\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m<ant-task>\n",
      "You are meant to re-write the text given to you in a simple, direct, and clear style.Follow these rules for communication:  \n",
      "1. **Use Simple Language**: Write plainly with short, straightforward sentences.  \n",
      "   - Example: \"I need help with this issue.\"  \n",
      "\n",
      "2. **Avoid AI-Giveaway Phrases**: Don't use clich√©s like \"dive into\" or \"unleash your potential.\"  \n",
      "   - Avoid: \"Let's dive into this game-changing solution.\"  \n",
      "   - Use instead: \"Here's how it works.\"  \n",
      "\n",
      "3. **Be Direct and Concise**: Remove unnecessary words and get to the point.  \n",
      "   - Example: \"We should meet tomorrow.\"  \n",
      "\n",
      "4. **Maintain a Natural Tone**: Write as you would speak. It's fine to start sentences with \"and\" or \"but.\"  \n",
      "   - Example: \"And that's why it matters.\"  \n",
      "\n",
      "5. **Avoid Marketing Language**: Don't use hype or promotional terms.  \n",
      "   - Avoid: \"This revolutionary product will transform your life.\"  \n",
      "   - Use instead: \"This product can help you.\"  \n",
      "\n",
      "6. **Keep It Honest**: Be real and avoid forced friendliness.  \n",
      "   - Example: \"I don't think that's the best idea.\"  \n",
      "\n",
      "7. **Simplify Grammar**: Perfect grammar isn't necessary. Casual styles, like lowercase \"i,\" are fine.  \n",
      "   - Example: \"i guess we can try that.\"  \n",
      "\n",
      "8. **Avoid Fluff**: Leave out unnecessary adjectives and adverbs.  \n",
      "   - Example: \"We finished the task.\"  \n",
      "\n",
      "9. **Focus on Clarity**: Make your writing easy to understand.  \n",
      "\n",
      "Always ensure your communication is approachable, clear, and practical. \n",
      "\n",
      "</ant-task>\n",
      "\n",
      "<ant-persona>\n",
      "A LinkedIn Influencer\n",
      "</ant-persona>\n",
      "\n",
      "<ant-constraints>\n",
      "\n",
      "Ensure that the response includes reasoning pathways that are actionable and informative.\n",
      "\n",
      "</ant-constraints>\n",
      "\n",
      "<ant-purpose>\n",
      "Your task is to dynamically unify the given components `<ant-task>` (input task or goal), `<ant-persona>` (the persona for defined input taks), and `<ant-constraints>` into a single, combined prompt.  \n",
      "The final prompt must be:\n",
      "  - A comprehensive integration of task content, persona‚Äôs viewpoint, and all specified constraints.\n",
      "  - Logically sound, cohesive, and reflective of all input components.\n",
      "  - Free of instructional commentary or format explanations in the output.\n",
      "The generated prompt must guide reasoning effectively and allow the assistant to interpret and respond dynamically.\n",
      "</ant-purpose>\n",
      "\n",
      "<ant-tagging-system>  \n",
      " While generating the unified prompt, you MUST ensure that the prompt contains the following prompt tag system implemented within it.Ensure that the tags are not limited to the following and can be expanded as needed:\n",
      " - `<assisstant-task>`: Represents the primary task or goal that needs to be refined, analyzed, or acted upon by the system or intelligent assistant.  \n",
      " - `<assisstant-constraints>`: Specifies restrictions, boundaries, or non-negotiable elements that must be respected during the processing of the prompt or task.  \n",
      " - `<assisstant-context>`: Encapsulates the purpose of the agent, user prompts, specialized critiques, and interactions, helping provide an overall understanding of the task.  \n",
      " - `<assisstant-instructions>`: Provides system-wide rules, protocols, and instructions to ensure consistency, coherence, and quality in processing all elements of the task.  \n",
      " - `<assisstant-steps>`: Outlines detailed steps that the system or agents are instructed to take to accomplish the tasks or refine the prompts.  \n",
      " - `<assisstant-reasoning>`: Specifies reasoning frameworks and methodologies (e.g., Tree of Thoughts, Meta-Prompting) for analyzing and refining tasks effectively.  \n",
      " - `<assisstant-output-instructions>`: Specifies exactly what should be output by the system or agents, often including formatting templates for achieving precise deliverables.  \n",
      " - `<assisstant-prompting-tags>`: Provides a predefined list of advanced prompting techniques (e.g., Role-based Reasoning, Iterative Deepening) that can guide task refinement.  \n",
      " - `<assisstant-task-X>`: Represents one of multiple input tasks (e.g., `<assisstant-task-1>`, `<assisstant-task-2>`) that can be synthesized or cross-referenced for refinement purposes.  \n",
      " - `<assisstant-action-steps>`: Defines actionable measures or guidance for refining or transforming a task or prompt dynamically and effectively.  \n",
      " **NOTE**: You are NOT being told to use all of these tags, but to ensure that the prompt contains the necessary tags for clarity and consistency and to use these to guide your understanding of the tagging system.\n",
      " **NOTE**: You MUST expand the tagging system. Use the above samples only to define your understanding of how it works and then Generate new tags where needed and use them thoroughly.\n",
      " Each Tag must be properly closed and opened and the content within them must be relevant to the task at hand.\n",
      " Example: `<sample-tag>`, `</sample-tag>`\n",
      " </ant-tagging-system>   \n",
      "\n",
      "<ant-context>\n",
      "Inputs to process for creating the unified prompt:\n",
      "1. `<ant-task>`: The initial task or goal requiring refinement and integration.\n",
      "2. `<ant-persona>`: Defined persona providing perspective, or a specific role for the assistant to adopt.\n",
      "3. `<ant-constraints>`: A set of restrictions, parameters, or non-negotiable elements that must be reflected in full in the final output.  \n",
      "4. `<ant-tagging-system>`: A predefined system of tags that must be serve as a baseline for tags implemented within the unified prompt for consistency and clarity.\n",
      "These elements collectively define the scope, tone, and boundaries of the unified task prompt.\n",
      "</ant-context>\n",
      "\n",
      "<ant-operating-instructions>\n",
      "- Begin by analyzing all three components (`<ant-task>`, `<ant-persona>`, `<ant-constraints>`) to fully understand their purpose, dependencies, and relationships among each other.\n",
      "- Understand each tag within the `<ant-tagging-system>` and their purpose in structuring the unified prompt effectively.\n",
      "- Utilize reasoning techniques to carefully integrate all inputs into a complete and logical prompt:\n",
      "  + Use **Least-To-Most Prompting** to break down the goal into simpler aspects, building toward a comprehensive reconstruction.\n",
      "  + Apply **Meta-Prompting** to reflect the persona‚Äôs role and constraints conceptually while ensuring alignment with the overall goal.\n",
      "  + Leverage **Tree of Thoughts** and **Reason + Action Prompting** to explore multiple options for merging the task, persona, and constraints into a single structure.\n",
      "  + Use **Role-Based Reasoning** to ensure the integrated persona's fits perfectly into the output prompt.\n",
      "- Dynamically adjust provided reasoning framework to maintain logical flow, adaptability under constraints, and alignment with key objectives.\n",
      "- Ensure that the final prompt is actionable, and fulfills all `<ant-constraints>` without any instructional commentary.\n",
      "- Use the `<ant-output-instructions>` to structure your final output, ensuring it meets all specified criteria and is ready for evaluation.\n",
      "</ant-operating-instructions>\n",
      "\n",
      "<ant-steps>\n",
      "1. **Understand the Inputs**:  \n",
      "  - Carefully read and analyze `<ant-task>`, `<ant-persona>`, and `<ant-constraints>`.  \n",
      "  - Identify the main goal of the task, the persona's perspective, and the constraints that must be adhered to in the final prompt.  \n",
      "\n",
      "2. **Understand the Tagging System**:  \n",
      "  - Review the `<ant-tagging-system>` to understand the predefined tags that must be included in the unified prompt.  \n",
      "  - Ensure that the tags are implemented effectively to maintain consistency and clarity in the output.\n",
      "  - Ensure that the tags told are only serving as a baseline and can be expanded as needed.\n",
      "\n",
      "3. **Break Down Relationships**:  \n",
      "  - Identify how the task, persona, and constraints connect to each other.  \n",
      "  - Find areas where the inputs support each other and where they might conflict or need adjustment to align.  \n",
      "  - Plot these connections step by step, identifying dependencies between elements and resolving conflicting components logically.  \n",
      "\n",
      "4. **Explore Different Paths**:  \n",
      "  - Start from the task‚Äôs core objective and generate different ways the persona and constraints can be combined into a cohesive structure.  \n",
      "  - For each path, consider how effectively it meets the task‚Äôs goals, respects the constraints, and incorporates the persona.  \n",
      "  - Analyze each option for strengths and weaknesses, ensuring no critical input is overlooked.  \n",
      "\n",
      "5. **Evaluate and Prune Paths**:  \n",
      "  - Reflect on the effectiveness and coherence of each path. Questions to consider:  \n",
      "    + Does this structure fully incorporate the persona‚Äôs influence on the task?  \n",
      "    + Are all constraints respected without weakening the task‚Äôs intent?  \n",
      "  - Remove paths that fail to meet these criteria or introduce contradictions, retaining only the most effective solutions.  \n",
      "\n",
      "6. **Iterate and Refine**:  \n",
      "  - Take the strongest remaining paths and refine them further, adding depth and clarity.  \n",
      "  - Focus on ensuring the final structure is logical, cohesive, and actionable while maintaining flexibility for interpretation.  \n",
      "\n",
      "7. **Finalize the Unified Prompt**:  \n",
      "  - Combine all key elements including task goals, persona framing, and constraints into a single, complete prompt.  \n",
      "  - Ensure the final result is actionable, clear, and reflective of all inputs without additional commentary or unnecessary complexity.\n",
      "\n",
      "8. **Implement the Tagging System**:  \n",
      "  - Embed the predefined tags from the `<ant-tagging-system>` into the unified prompt.  \n",
      "  - Ensure that each tag is used appropriately and that the prompt is structured according to the tagging system guidelines.\n",
      "</ant-steps>\n",
      "\n",
      "<ant-reasoning>\n",
      "Use structured reasoning techniques for crafting the unified prompt:\n",
      "1. **Least-To-Most Prompting**: Simplify the task into layers, then iteratively reconstruct to ensure comprehensive integration.\n",
      "2. **Tree of Thoughts**: Explore multiple pathways for merging key elements (task goals, persona framing, constraints) dynamically.\n",
      "3. **Role-Based Reasoning**: Integrate the persona‚Äôs perspective organically. Reflect on how the assistant‚Äôs role enhances the task.\n",
      "4. **Dynamic Adjustments**: Use feedback loops (e.g., self-ask analysis) to refine logical coherence and strengthen alignment between inputs.\n",
      "5. **Iterative Deepening**: Reassess and refine by layering additional insights at every stage of integration, ensuring complete adherence to constraints.\n",
      "</ant-reasoning>\n",
      "\n",
      "<ant-output-instructions>\n",
      "- Your output must include:\n",
      "    - **Unified Prompt**: Provide a single, complete task prompt that integrates `<ant-task>`, `<ant-persona>`, and `<ant-constraints>` cohesively.\n",
      "    - **Key Qualities of the Unified Prompt**:\n",
      "        + Reflects all inputs seamlessly with no omissions or contradictions.\n",
      "        + Aligns `<ant-task>` objectives with the persona role dynamically and adheres strictly to `<ant-constraints>`.\n",
      "        + Ensures logical clarity, adaptability, and coherence, allowing for dynamic reasoning within the assistant‚Äôs response.\n",
      "    - **Do NOT Include Instructional Text**:\n",
      "        + Provide only the fully synthesized prompt without explanation, meta-commentary, or formatting guides.\n",
      "    - **Tagging System Implementation**:\n",
      "        + Ensure that the predefined tags from `<ant-tagging-system>` are embedded within the unified prompt for consistency and clarity.\n",
      "        + Use the tags appropriately to structure the prompt effectively and maintain logical flow.\n",
      "        + Expand the tagging system as needed to enhance the prompt‚Äôs structure and readability.\n",
      "</ant-output-instructions>\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHead of Prompt Engineering\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "<assisstant-context>  \n",
      "You need to rewrite a text clearly and simply while adopting the tone of a LinkedIn influencer, maintaining directness and approachability.  \n",
      "</assisstant-context>  \n",
      "\n",
      "<assisstant-task>  \n",
      "Rewrite the provided text in a simple, direct, and clear style, ensuring that it communicates effectively without complex language or marketing hype.  \n",
      "</assisstant-task>  \n",
      "\n",
      "<assisstant-constraints>  \n",
      "- Use simple language with short sentences.  \n",
      "- Avoid clich√©s and promotional phrases.  \n",
      "- Be direct and concise, cutting out unnecessary words.  \n",
      "- Maintain a natural tone, allowing informalities.  \n",
      "- Write honestly without forced friendliness.  \n",
      "- Simplify grammar usage.  \n",
      "- Exclude unnecessary fluff or adjectives.  \n",
      "- Focus on clarity and ease of understanding.  \n",
      "</assisstant-constraints>  \n",
      "\n",
      "<assisstant-reasoning>  \n",
      "Utilize clear and structured processes for rewriting that will ensure adherence to the constraints and persona's voice without sacrificing clarity or intent.  \n",
      "</assisstant-reasoning>  \n",
      "\n",
      "<assisstant-output-instructions>  \n",
      "Provide the rewritten text in a format that embodies the specified constraints and tone.  \n",
      "</assisstant-output-instructions>  \n",
      "\n",
      "<assisstant-action-steps>  \n",
      "1. Identify the key messages within the given text.  \n",
      "2. Break down complex sentences into shorter, simpler forms.  \n",
      "3. Remove any jargon or marketing language used.  \n",
      "4. Retain the essential information while making it more approachable.  \n",
      "5. Ensure the final output aligns with the natural, conversational tone of a LinkedIn influencer.  \n",
      "</assisstant-action-steps>  \n",
      "\n",
      "<assisstant-prompting-tags>  \n",
      "<meta-prompting>Rewrite in clear, simple language suitable for a LinkedIn audience.</meta-prompting>  \n",
      "<role-based-reasoning>Emphasize a natural and honest tone throughout the rewrite.</role-based-reasoning>  \n",
      "</assisstant-prompting-tags>\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PromptCrew=InitialPromptCrew.kickoff(inputs={\"LaymanPrompt\":LaymanPrompt,\"Persona\":Persona,\"Constraints\":Constraints})\n",
    "InitialPrompt=PromptCrew.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73535e6f",
   "metadata": {},
   "source": [
    "#### Dynamic Agents Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4617c4",
   "metadata": {},
   "source": [
    "Generation and formatting of Dynamic Agents on the Basis of Pydantic Base Models.\n",
    "- ``AgentCount`` Defines the list of Dynamic Agent Objects to be created by crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06752e3-92c0-41d2-9506-361e6f22dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mDynamic Agent Manager\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m<ant-task>\n",
      "<assisstant-context>  \n",
      "You need to rewrite a text clearly and simply while adopting the tone of a LinkedIn influencer, maintaining directness and approachability.  \n",
      "</assisstant-context>  \n",
      "\n",
      "<assisstant-task>  \n",
      "Rewrite the provided text in a simple, direct, and clear style, ensuring that it communicates effectively without complex language or marketing hype.  \n",
      "</assisstant-task>  \n",
      "\n",
      "<assisstant-constraints>  \n",
      "- Use simple language with short sentences.  \n",
      "- Avoid clich√©s and promotional phrases.  \n",
      "- Be direct and concise, cutting out unnecessary words.  \n",
      "- Maintain a natural tone, allowing informalities.  \n",
      "- Write honestly without forced friendliness.  \n",
      "- Simplify grammar usage.  \n",
      "- Exclude unnecessary fluff or adjectives.  \n",
      "- Focus on clarity and ease of understanding.  \n",
      "</assisstant-constraints>  \n",
      "\n",
      "<assisstant-reasoning>  \n",
      "Utilize clear and structured processes for rewriting that will ensure adherence to the constraints and persona's voice without sacrificing clarity or intent.  \n",
      "</assisstant-reasoning>  \n",
      "\n",
      "<assisstant-output-instructions>  \n",
      "Provide the rewritten text in a format that embodies the specified constraints and tone.  \n",
      "</assisstant-output-instructions>  \n",
      "\n",
      "<assisstant-action-steps>  \n",
      "1. Identify the key messages within the given text.  \n",
      "2. Break down complex sentences into shorter, simpler forms.  \n",
      "3. Remove any jargon or marketing language used.  \n",
      "4. Retain the essential information while making it more approachable.  \n",
      "5. Ensure the final output aligns with the natural, conversational tone of a LinkedIn influencer.  \n",
      "</assisstant-action-steps>  \n",
      "\n",
      "<assisstant-prompting-tags>  \n",
      "<meta-prompting>Rewrite in clear, simple language suitable for a LinkedIn audience.</meta-prompting>  \n",
      "<role-based-reasoning>Emphasize a natural and honest tone throughout the rewrite.</role-based-reasoning>  \n",
      "</assisstant-prompting-tags>\n",
      "</ant-task>\n",
      "\n",
      "<ant-instructions>\n",
      "    - Before responding, analyze this prompt and all its components thoroughly.\n",
      "    - Ensure that the final answer is generated with a **singular focus on refining `<ant-task>`** and NOT producing its output.\n",
      "    - Ensure that the agents goals are stritctly not towards discussing the content of `<ant-task>` directly but creating the best possible task definition for the next intelligent assistant.\n",
      "    - Ensure that the team composition explicitly aims to **improve the identified task definition improvement crities of `<ant-task>`**, enabling it to prompt the intelligent assistant that is going to be presented the refined version to effectively generate the best possible outputs.\n",
      "    - Ensure that the **agent-goals** clearly state how the agents' optimizations contribute to refining `<ant-task>`, focusing on improving the identified criterias in `<ant-steps>`.\n",
      "    - Ensure that the **agent-tasks** contain detailed, step-by-step contributions that involve **refining `<ant-task>` itself** using targeted prompting and reasoning techniques, avoiding references to `<ant-task>`'s eventual output or generated content.\n",
      "    - Do not include redundant tasks or roles. Each team member's contribution must be as distinct and non-overlapping as possible.\n",
      "    - Follow the steps outlined in `<ant-steps>` to achieve the desired outcome.\n",
      "    - Utilize the reasoning techniques specified in `<ant-reasoning>` to guide your thinking process.\n",
      "    - Avoid focus on the ethical concerns regarding `<ant-task>` while deciding on the team composition.\n",
      "    - Do not create roles that are not directly related to refining `<ant-task>` i.e \"Team Collaboration Expert\" since each agent will be working independently on refining the task.\n",
      "</ant-instructions>\n",
      "\n",
      "<ant-steps>\n",
      "    1. **Analyze** the task specified in `<ant-task>` from multiple perspectives to ensure it yields the best possible results.\n",
      "    2. **Devise** a dynamic and efficient team consisting of 3 members to collaboratively refine `<ant-task>` into a more effective prompt for generating high-quality outcomes with an intelligent assistant.\n",
      "    3. **Figure out** areas of improvement in `<ant-task>`'s task defintion that can be addressed by the team members' specialized expertise. \n",
      "        - Analyze Various Aspects of the Task Definition in `<ant-task>` which require improvement to make a better defined task for the assisstant.\n",
      "        - Prune the Aspects analyzed which related to the content of the task itself and only keep those which are relevent to creating the best possible task definition.\n",
      "        - Each Identified Aspect must be focused at creating the best possible version of the task definition `<ant-task>` so the intelligent assistant can generate the best possible output.\n",
      "        - The following are some examples of aspects that can be improved in `<ant-task>` to define your way of thinking:\n",
      "            - Clarity of the task definition.\n",
      "            - Adaptability of the task definition.\n",
      "            - Goal Alignment of the task definition.\n",
      "            - Constraints of the task definition.\n",
      "            - Reasoning Depth of the task definition.\n",
      "            - Researched Depth of the task definition.\n",
      "            - Precision and Tone of the task definition.\n",
      "            - Effectiveness of Guidance in the task definition.\n",
      "            - Quality of the Tagging System in the task definition.\n",
      "    4. **Brainstorm** ways in which each team member can uniquely contribute to the optimization of the aspects previously identified. The goal is to create a team that optimizes `<ant-task>` itself for effectively taking action on identified criterias.\n",
      "    5. **Format** the selected team systematically, outlining the following attributes for each member:\n",
      "        - `<agent-name>` must clearly state the role of the team member, such as \"___ Expert\" which corresponds to their specific contribution toward refining `<ant-task>`.\n",
      "        - `<agent-goal>` must include a detailed description of the unique goal for improving `<ant-task>`.\n",
      "        - `<agent-backstory>` must describe the ideal background, skillset, and motivation for each role, presenting why they are suited for optimizing `<ant-task>`.\n",
      "        - `<agent-task>` must explain, in a structured and detailed manner, the specific steps the team member must perform to refine the tagged task definition in `<ant-task>` using advanced prompting and reasoning techniques, ensuring their task contribution is focused and non-overlapping with others so the best possible assignment is created for the next intelligent assisstant.\n",
      "    6. **Respond** with the finalized team selection using the format specified in `<ant-output-instructions>`.\n",
      "</ant-steps>\n",
      "\n",
      "<ant-reasoning>\n",
      "Use structured reasoning techniques to dynamically assess and optimize the refinement process and team composition:\n",
      "  1. **Dynamic Role Identification**: Look for specific gaps or inefficiencies in `<ant-task>`, and reason about what kind of expertise is required to improve those areas dynamically.  \n",
      "  2. **Layered Improvements**: Assign each agent iterative tasks that include analyzing problems, revising solutions, and working towards the identified aspects of `<ant-task>`. Ensure reasoning remains present throughout.  \n",
      "  3. **Collaborative Alignment**: Ensure the roles and tasks of the team complement each other logically, without redundancy or conflicts, to create a parallel improvement of `<ant-task>`.  \n",
      "  4. **Iterative Refinement Loops**: Integrate reasoning cycles that allow agents to revisit and refine their contributions dynamically, testing whether proposed solutions enhance the task‚Äôs purpose while respecting constraints.  \n",
      "</ant-reasoning>\n",
      "\n",
      "<ant-output-instructions>\n",
      "    - The output must consist of a series of `<ant-output-object>` entries devised through the steps in `<ant-steps>`.\n",
      "    - Only include the highest-priority and most impactful `<ant-output-object>` set of entries identified through the analysis.\n",
      "    - Do not include any instructional text apart from the formatted `<ant-output-object>` attributes.\n",
      "    - Ensure `<agent-backstory>` in each `<ant-output-object>` is phrased as a personal introduction (e.g., \"You are a...\").\n",
      "    - Ensure `<agent-goal>` in each `<ant-output-object>` is phrased as a mission statement (e.g., \"As an `<agent-name>`, Your goal...\").\n",
      "    - Ensure that you reference to `<ant-task>` in the `<agent-task>` attribute for each agent, explaining how its going to refine it by utilizing Chain of Thoughts.\n",
      "    **NOTE** : if `<agent-task>` is not related to refining `<ant-task>` it will be considered as an invalid response and will ruin the entire system.\n",
      "    **NOTE** : `<ant-task>` is the task that needs to be refined and `<ant-output-object>` defines the agents that will refine the task and **NOT** create a deliverable or refine the content for the task itself.\n",
      "</ant-output-instructions>\n",
      "\n",
      "<ant-output-object>\n",
      "    Agent Name = `<agent-name>`\n",
      "    Agent Goal = `<agent-goal>`\n",
      "    Agent Backstory = `<agent-backstory>`\n",
      "    Agent Task = `<agent-task>`\n",
      "</ant-output-object>\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mDynamic Agent Manager\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "<ant-output-object>  \n",
      "    Agent Name = `Clarity Expert`  \n",
      "    Agent Goal = `As a Clarity Expert, your goal is to enhance the clarity of the task definition in <ant-task> by simplifying complex phrases and ensuring straightforward communication.`  \n",
      "    Agent Backstory = `You are a communication specialist with over 10 years of experience in writing and editing. Your background includes working with various organizations to refine their messaging for clarity and impact. You have a knack for breaking down complicated ideas into simple, digestible formats, making you well-suited to improve <ant-task>.`  \n",
      "    Agent Task = `Analyze the existing text in <ant-task> to identify complex phrases and jargon. Rewrite these sections using simpler language and shorter sentences. Ensure that the key messages are retained while enhancing overall readability and comprehension.`  \n",
      "</ant-output-object>  \n",
      "\n",
      "<ant-output-object>  \n",
      "    Agent Name = `Tone Specialist`  \n",
      "    Agent Goal = `As a Tone Specialist, your goal is to ensure that the tone of the task definition in <ant-task> aligns with a direct and approachable style suitable for a LinkedIn audience.`  \n",
      "    Agent Backstory = `You are a seasoned content creator with a strong background in social media and professional networking. Having worked with various influencers, you understand how to convey messages in a relatable and engaging manner. Your expertise in tone adaptation makes you an ideal candidate to refine <ant-task>.`  \n",
      "    Agent Task = `Review the tone of the text in <ant-task> and identify areas where the language may come off as overly formal or promotional. Adjust the wording to create a more conversational and approachable tone while maintaining professionalism. Ensure the final output feels natural and engaging for the intended audience.`  \n",
      "</ant-output-object>  \n",
      "\n",
      "<ant-output-object>  \n",
      "    Agent Name = `Constraint Analyst`  \n",
      "    Agent Goal = `As a Constraint Analyst, your goal is to evaluate and refine the constraints outlined in <ant-task> to ensure they effectively guide the rewriting process without being overly restrictive.`  \n",
      "    Agent Backstory = `You are a project manager with extensive experience in defining and managing project constraints. Your analytical skills allow you to assess the effectiveness of guidelines and make necessary adjustments. Your ability to balance flexibility with structure makes you well-equipped to enhance <ant-task>.`  \n",
      "    Agent Task = `Examine the constraints provided in <ant-task> to identify any that may be too limiting or unclear. Propose revisions that maintain the intent of the constraints while allowing for greater creativity and adaptability in the rewriting process. Ensure that the constraints are straightforward and facilitate the desired outcomes.`  \n",
      "</ant-output-object>\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AgentCount=3\n",
    "AgentsListRaw=DynamicAgentCreationCrew.kickoff(inputs={\"InitialTask\":InitialPrompt,\"AgentCount\":str(AgentCount)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b795c7d5-3d83-4adb-94c9-cee4e765efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentInputs = []\n",
    "for agent in AgentsListRaw.pydantic.agents:\n",
    "    AgentInputs.append(\n",
    "        {\n",
    "            \"AgentName\":agent.agent_name,\n",
    "            'AgentBackstory':agent.agent_backstory,\n",
    "            'AgentGoal':agent.agent_goal,\n",
    "            'AgentTask':agent.agent_task,\n",
    "            \"InitialTask\":InitialPrompt\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30bd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(agent_inputs):\n",
    "    agent = Agents.Agent(\n",
    "        role = agent_inputs['AgentName'],\n",
    "        goal = agent_inputs['AgentGoal'],\n",
    "        backstory = agent_inputs['AgentBackstory'],\n",
    "        verbose = False,\n",
    "        llm = Agents.LLM(\n",
    "        model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        ),\n",
    "        temperature = 0.4\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcefc8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AgentName': 'Clarity Specialist',\n",
       "  'AgentBackstory': 'You are a communication expert with a background in linguistics and experience in editing technical documents. Your passion lies in making complicated ideas accessible to everyone, and you have worked with various organizations to refine their messaging for broader audiences.',\n",
       "  'AgentGoal': 'As a Clarity Specialist, your goal is to enhance the clarity of the task definition in `<ant-task>` by simplifying complex phrases and ensuring the message is straightforward and easy to understand.',\n",
       "  'AgentTask': 'Review the task definition in `<ant-task>` methodically, identifying areas where language can be simplified. Focus on removing jargon and complex phrases, ensuring that the revised task is direct and clear. Provide a revised version that maintains the original intent while enhancing readability.',\n",
       "  'InitialTask': '<assisstant-context>\\nAs a LinkedIn Influencer, participate in refining the communication style of a given text to ensure clarity and simplicity. This exercise aligns with creating content that is approachable and direct for an audience who appreciates straightforward and authentic communication. \\n</assisstant-context>\\n\\n<assisstant-task>\\nRevise the text provided to you. Ensure that it adheres to the principles of simple and clear communication by removing complexity and unnecessary marketing language while making sure the final message is direct, honest, and easy to understand.\\n</assisstant-task>\\n\\n<assisstant-constraints>\\n- Use simple, understandable language without clich√©s or marketing jargon.\\n- Be direct, concise, and maintain a natural, conversational tone, similar to everyday speech.\\n- Remove any fluff, ensuring clarity and practicality in the message.\\n- Avoid unnecessary grammatical perfection. It is okay to use casual language.\\n</assisstant-constraints>\\n\\n<assisstant-instructions>\\nAdopt a reasoning pathway that includes:\\n- Identifying areas where the current text could be simplified.\\n- Ensuring the message remains genuine without forced friendliness.\\n- Maintaining focus on being clear and direct to ensure the audience easily grasps the main points.\\n</assisstant-instructions>\\n\\n<assisstant-steps>\\n1. Review the text methodically, identifying complex phrases and unnecessary words.\\n2. Simplify sentence structures to make them more direct and straightforward.\\n3. Replace marketing terms with plain language that reflects honesty and authenticity.\\n4. Ensure the revised text flows naturally, echoing a conversational style.\\n5. Double-check that the message is clear and concise without losing its original intent.\\n</assisstant-steps>\\n\\n<assisstant-output-instructions>\\nThe final output should be a revised version of the text that:\\n- Reflects a simple, clear style of communication.\\n- Adheres strictly to the given constraints.\\n- Includes instructions to maintain an honest and natural tone, with direct language.\\n- Is suitable for expanding engagement as a LinkedIn Influencer seeking clarity and connection with an audience.\\n</assisstant-output-instructions>'},\n",
       " {'AgentName': 'Tone Consultant',\n",
       "  'AgentBackstory': 'You are a seasoned content creator with a background in marketing and social media. Your expertise lies in crafting messages that resonate with audiences, and you have a knack for striking the right balance between professionalism and approachability.',\n",
       "  'AgentGoal': 'As a Tone Consultant, your goal is to ensure that the tone of the task definition in `<ant-task>` is natural and conversational, making it relatable for the audience.',\n",
       "  'AgentTask': 'Analyze the tone of the task definition in `<ant-task>`, identifying areas where the language may come off as overly formal or insincere. Revise the text to adopt a more conversational tone, ensuring that it feels authentic and engaging while still being direct and clear.',\n",
       "  'InitialTask': '<assisstant-context>\\nAs a LinkedIn Influencer, participate in refining the communication style of a given text to ensure clarity and simplicity. This exercise aligns with creating content that is approachable and direct for an audience who appreciates straightforward and authentic communication. \\n</assisstant-context>\\n\\n<assisstant-task>\\nRevise the text provided to you. Ensure that it adheres to the principles of simple and clear communication by removing complexity and unnecessary marketing language while making sure the final message is direct, honest, and easy to understand.\\n</assisstant-task>\\n\\n<assisstant-constraints>\\n- Use simple, understandable language without clich√©s or marketing jargon.\\n- Be direct, concise, and maintain a natural, conversational tone, similar to everyday speech.\\n- Remove any fluff, ensuring clarity and practicality in the message.\\n- Avoid unnecessary grammatical perfection. It is okay to use casual language.\\n</assisstant-constraints>\\n\\n<assisstant-instructions>\\nAdopt a reasoning pathway that includes:\\n- Identifying areas where the current text could be simplified.\\n- Ensuring the message remains genuine without forced friendliness.\\n- Maintaining focus on being clear and direct to ensure the audience easily grasps the main points.\\n</assisstant-instructions>\\n\\n<assisstant-steps>\\n1. Review the text methodically, identifying complex phrases and unnecessary words.\\n2. Simplify sentence structures to make them more direct and straightforward.\\n3. Replace marketing terms with plain language that reflects honesty and authenticity.\\n4. Ensure the revised text flows naturally, echoing a conversational style.\\n5. Double-check that the message is clear and concise without losing its original intent.\\n</assisstant-steps>\\n\\n<assisstant-output-instructions>\\nThe final output should be a revised version of the text that:\\n- Reflects a simple, clear style of communication.\\n- Adheres strictly to the given constraints.\\n- Includes instructions to maintain an honest and natural tone, with direct language.\\n- Is suitable for expanding engagement as a LinkedIn Influencer seeking clarity and connection with an audience.\\n</assisstant-output-instructions>'},\n",
       " {'AgentName': 'Practicality Advisor',\n",
       "  'AgentBackstory': 'You are a project manager with extensive experience in leading teams and executing projects efficiently. Your focus is on creating actionable plans that are easy to follow, and you have a proven track record of improving processes for better outcomes.',\n",
       "  'AgentGoal': 'As a Practicality Advisor, your goal is to enhance the practicality of the task definition in `<ant-task>` by ensuring that the instructions are actionable and straightforward.',\n",
       "  'AgentTask': 'Examine the task definition in `<ant-task>` for any elements that may be vague or impractical. Suggest specific changes that make the instructions clearer and more actionable, ensuring that the audience can easily grasp the steps they need to take.',\n",
       "  'InitialTask': '<assisstant-context>\\nAs a LinkedIn Influencer, participate in refining the communication style of a given text to ensure clarity and simplicity. This exercise aligns with creating content that is approachable and direct for an audience who appreciates straightforward and authentic communication. \\n</assisstant-context>\\n\\n<assisstant-task>\\nRevise the text provided to you. Ensure that it adheres to the principles of simple and clear communication by removing complexity and unnecessary marketing language while making sure the final message is direct, honest, and easy to understand.\\n</assisstant-task>\\n\\n<assisstant-constraints>\\n- Use simple, understandable language without clich√©s or marketing jargon.\\n- Be direct, concise, and maintain a natural, conversational tone, similar to everyday speech.\\n- Remove any fluff, ensuring clarity and practicality in the message.\\n- Avoid unnecessary grammatical perfection. It is okay to use casual language.\\n</assisstant-constraints>\\n\\n<assisstant-instructions>\\nAdopt a reasoning pathway that includes:\\n- Identifying areas where the current text could be simplified.\\n- Ensuring the message remains genuine without forced friendliness.\\n- Maintaining focus on being clear and direct to ensure the audience easily grasps the main points.\\n</assisstant-instructions>\\n\\n<assisstant-steps>\\n1. Review the text methodically, identifying complex phrases and unnecessary words.\\n2. Simplify sentence structures to make them more direct and straightforward.\\n3. Replace marketing terms with plain language that reflects honesty and authenticity.\\n4. Ensure the revised text flows naturally, echoing a conversational style.\\n5. Double-check that the message is clear and concise without losing its original intent.\\n</assisstant-steps>\\n\\n<assisstant-output-instructions>\\nThe final output should be a revised version of the text that:\\n- Reflects a simple, clear style of communication.\\n- Adheres strictly to the given constraints.\\n- Includes instructions to maintain an honest and natural tone, with direct language.\\n- Is suitable for expanding engagement as a LinkedIn Influencer seeking clarity and connection with an audience.\\n</assisstant-output-instructions>'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e134c",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e2913",
   "metadata": {},
   "source": [
    "#### GA Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd0a65",
   "metadata": {},
   "source": [
    "Includes the Primary GA Setup Including the following:\n",
    "- ``PromptGene`` Class Definition.\n",
    "- ``Gene Generation`` and ``Gene Management`` Functions.\n",
    "- ``Population Generation`` for GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e35af6-208c-44d0-bd83-fb4fd6bca614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGene:\n",
    "    \n",
    "    def __init__(self,initial_prompt=\"\", agent_guidance=\"\", agent_critique=\"\", refined_prompt=\"\", result=\"\", action_steps=\"\", general_score=0, reasoning_score=0, refined_prompt_critique=\"\"):\n",
    "        self.InitialPrompt = initial_prompt\n",
    "        self.AgentGuidance = agent_guidance\n",
    "        self.AgentCritique = agent_critique\n",
    "        self.RefinedPrompt = refined_prompt\n",
    "        self.Result = result\n",
    "        self.ActionSteps = action_steps\n",
    "        self.GeneralScore = general_score\n",
    "        self.ReasoningScore = reasoning_score\n",
    "        self.RefinedPromptCritique = refined_prompt_critique\n",
    "    \n",
    "    \n",
    "\n",
    "    def display(self):\n",
    "        print(f\"\\n\\n\\n\\n\\nInitial Prompt: {self.InitialPrompt}\")\n",
    "        print(f\"\\n\\n\\n\\n\\nAgent Guidance: {self.AgentGuidance}\")\n",
    "        print(f\"\\n\\n\\n\\n\\nAgent Critique: {self.AgentCritique}\")\n",
    "        print(f\"\\n\\n\\n\\n\\nRefined Prompt: {self.RefinedPrompt}\")\n",
    "        print(f\"\\n\\n\\n\\n\\nResult: {self.Result}\")\n",
    "        print(f\"\\n\\n\\n\\n\\nAction Steps: {self.ActionSteps}\")\n",
    "        print(f\"\\n\\n\\n\\n\\nGeneral Score: {self.GeneralScore}\")\n",
    "        print(f\"\\nReasoning Score: {self.ReasoningScore}\")\n",
    "        print(f\"\\nTotal Score: {self.GeneralScore+self.ReasoningScore}\")    \n",
    "        print(f\"\\n\\n\\n\\n\\nRefined Prompt Critique: {self.RefinedPromptCritique}\")\n",
    "\n",
    "\n",
    "    def get(self):\n",
    "        inputArr={\n",
    "            'InitialTask': self.InitialPrompt, \n",
    "            'SpecializedGuidance': self.AgentGuidance,\n",
    "            'RefinedTask': self.RefinedPrompt, \n",
    "            'RefinedTaskOutput': self.Result\n",
    "        }\n",
    "        return inputArr\n",
    "\n",
    "    def generateEval(self):\n",
    "        GeneralScore=PromptGeneralEvaluationCrew.kickoff(self.get())\n",
    "        ReasoningScore=PromptReasoningEvaluationCrew.kickoff(self.get())\n",
    "        inputs=self.get()\n",
    "        CritiqueEval=PromptCritiqueEvaluationCrew.kickoff(inputs={\n",
    "            'InitialTask': inputs['InitialTask'],\n",
    "            'SpecializedGuidance': inputs['SpecializedGuidance'],\n",
    "            'RefinedTask': inputs['RefinedTask'],\n",
    "            'RefinedTaskOutput': inputs['RefinedTaskOutput'],\n",
    "            'GeneralEvaluation': GeneralScore.raw,\n",
    "            'ReasoningEvaluation': ReasoningScore.raw\n",
    "        })\n",
    "        self.GeneralScore=GeneralScore.pydantic.ScoreOutof90\n",
    "        self.ReasoningScore=ReasoningScore.pydantic.ScoreOutof70\n",
    "        self.ActionSteps=CritiqueEval.pydantic.ActionableSteps\n",
    "        self.RefinedPromptCritique=CritiqueEval.pydantic.RefinedPromptCritique\n",
    "        return self.GeneralScore+self.ReasoningScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3555c99c-f82c-4312-a6d0-fd88226ab142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGene(InitialPrompt, CrtiqueReport, LayerCrew):\n",
    "    GenePromptResult=LayerCrew.kickoff(inputs={\"InitialTask\":InitialPrompt,\"SpecializedGuidance\":CrtiqueReport.SpecializedGuidance,\"SpecializedCritique\":CrtiqueReport.SpecializedCritique})\n",
    "    GenePrompt=GenePromptResult.raw\n",
    "    GeneOutput=Agents.InvokeGpt4oMini(prompt=GenePrompt)\n",
    "    Gene=PromptGene(InitialPrompt,CrtiqueReport.SpecializedGuidance,CrtiqueReport.SpecializedCritique,GenePrompt,GeneOutput)\n",
    "    Gene.generateEval()\n",
    "    return Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73925cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGeneFromPrompt(PrimaryPrompt,AgentInputs):\n",
    "    UpdatedCritique=InitialCritiqueCrew.kickoff(inputs={\n",
    "        'InitialTask':PrimaryPrompt,\n",
    "        'AgentName':AgentInputs['AgentName'],\n",
    "        'AgentBackstory':AgentInputs['AgentBackstory'],\n",
    "        'AgentGoal':AgentInputs['AgentGoal'],\n",
    "        'AgentTask':AgentInputs['AgentTask']\n",
    "    })\n",
    "    PromptGenerator=Agents.GetCrewWithAgent(\n",
    "        Agent=get_agent(AgentInputs),\n",
    "        TaskYamlFile= os.path.join(base_dir, \"definitions\", \"TaskDef\", \"SpecializedPromptGeneration.yaml\"),\n",
    "        OutputFile= os.path.join(base_dir, \"logs\", \"SpecializedPromptLogs.txt\"),\n",
    "    )\n",
    "    NewGene=GenerateGene(PrimaryPrompt,UpdatedCritique.pydantic,PromptGenerator)\n",
    "    return NewGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "409bce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_tasks_async_custom(Agents, InputPerAgent, InputData):\n",
    "    tasks = []\n",
    "    num_agents = len(Agents)\n",
    "\n",
    "    for i in range(len(InputData)):\n",
    "        agent_index = (i // InputPerAgent) % num_agents\n",
    "        tasks.append(Agents[agent_index].kickoff_async(inputs=InputData[i]))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9521d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def generate_population_async(initial_prompt, agent_inputs , population_size):    \n",
    "\n",
    "    InputData=[]\n",
    "    PromptGenerators=[]\n",
    "    for agent_input in agent_inputs:\n",
    "        for i in range(population_size):\n",
    "            InputData.append({\n",
    "                'InitialTask':initial_prompt,\n",
    "                'AgentName':agent_input['AgentName'],\n",
    "                'AgentBackstory':agent_input['AgentBackstory'],\n",
    "                'AgentGoal':agent_input['AgentGoal'],\n",
    "                'AgentTask':agent_input['AgentTask']\n",
    "            })\n",
    "        PromptGenerator=Agents.GetCrewWithAgent(\n",
    "            Agent=get_agent(agent_input),\n",
    "            TaskYamlFile= os.path.join(base_dir, \"definitions\", \"TaskDef\", \"SpecializedPromptGeneration.yaml\"),\n",
    "            OutputFile= os.path.join(base_dir, \"logs\", \"SpecializedPromptLogs.txt\"),\n",
    "            Async=True\n",
    "        )\n",
    "        PromptGenerators.append(PromptGenerator)\n",
    "\n",
    "    UpdatedCritiques = await InitialCritiqueCrew.kickoff_for_each_async(inputs=InputData)\n",
    "\n",
    "\n",
    "    InputData=[]\n",
    "    for i in range(len(UpdatedCritiques)):\n",
    "        InputData.append({\n",
    "            'InitialTask':initial_prompt,\n",
    "            'SpecializedGuidance':UpdatedCritiques[i].pydantic.SpecializedGuidance,\n",
    "            'SpecializedCritique':UpdatedCritiques[i].pydantic.SpecializedCritique\n",
    "        })\n",
    "    UpdatedPrompts=await run_tasks_async_custom(PromptGenerators,population_size,InputData)\n",
    "\n",
    "    UpdatedRawPrompts=[UpdatedPrompts[i].raw for i in range(len(UpdatedCritiques))]\n",
    "    GeneOutputs=await Agents.gather_responses(UpdatedRawPrompts)\n",
    "\n",
    "    NewGenes=[]\n",
    "    for i in range(len(UpdatedCritiques)):\n",
    "        NewGene=PromptGene(initial_prompt,UpdatedCritiques[i].pydantic.SpecializedGuidance,UpdatedCritiques[i].pydantic.SpecializedCritique,UpdatedPrompts[i].raw,GeneOutputs[i])\n",
    "        NewGenes.append(NewGene)\n",
    "    \n",
    "    InputData=[]\n",
    "    for i in range(len(NewGenes)):\n",
    "        InputData.append(NewGenes[i].get())\n",
    "\n",
    "    GeneralScores= await PromptGeneralEvaluationCrew.kickoff_for_each_async(inputs=InputData)\n",
    "    ReasoningScores= await  PromptReasoningEvaluationCrew.kickoff_for_each_async(inputs=InputData)\n",
    "\n",
    "    InputData=[]\n",
    "    for i in range(len(NewGenes)):\n",
    "        InputData.append({\n",
    "            'InitialTask': NewGenes[i].InitialPrompt,\n",
    "            'SpecializedGuidance': NewGenes[i].AgentGuidance,\n",
    "            'RefinedTask': NewGenes[i].RefinedPrompt,\n",
    "            'RefinedTaskOutput': NewGenes[i].Result,\n",
    "            'GeneralEvaluation': GeneralScores[i].raw,\n",
    "            'ReasoningEvaluation': ReasoningScores[i].raw\n",
    "        })\n",
    "\n",
    "    \n",
    "    CritiqueEvals=  await PromptCritiqueEvaluationCrew.kickoff_for_each_async(inputs=InputData)\n",
    "\n",
    "    for i in range(population_size):\n",
    "        NewGenes[i].GeneralScore=GeneralScores[i].pydantic.ScoreOutof90\n",
    "        NewGenes[i].ReasoningScore=ReasoningScores[i].pydantic.ScoreOutof70\n",
    "        NewGenes[i].RefinedPromptCritique=CritiqueEvals[i].pydantic.RefinedPromptCritique\n",
    "        NewGenes[i].ActionSteps=CritiqueEvals[i].pydantic.ActionableSteps\n",
    "\n",
    "    Genes=[]\n",
    "    for i in range(len(agent_inputs)):\n",
    "        AgentGenes=[]\n",
    "        for y in range(population_size):\n",
    "            AgentGenes.append(NewGenes[i*population_size+y])\n",
    "        Genes.append(AgentGenes)\n",
    "\n",
    "    \n",
    "    return Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99499df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "PopulationList=await generate_population_async(InitialPrompt, AgentInputs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eca01d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<__main__.PromptGene at 0x230d007cf90>,\n",
       "  <__main__.PromptGene at 0x230d1be9f90>,\n",
       "  <__main__.PromptGene at 0x230d15681d0>],\n",
       " [<__main__.PromptGene at 0x230d00b7c90>,\n",
       "  <__main__.PromptGene at 0x230cfe9dfd0>,\n",
       "  <__main__.PromptGene at 0x230d1c45010>],\n",
       " [<__main__.PromptGene at 0x230d0046390>,\n",
       "  <__main__.PromptGene at 0x230d0044d50>,\n",
       "  <__main__.PromptGene at 0x230d0045ad0>]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PopulationList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc668ab",
   "metadata": {},
   "source": [
    "#### GA Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b5461e",
   "metadata": {},
   "source": [
    "General GA Function Defintions are present including helper functions for ``Crossover``, ``Mutation`` & ``Termination``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b09f42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2cf66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def CrossoverMutatePrompts(PrimaryPopulation,SecondaryPopulation,MutationPopulation,AgentInputs):\n",
    "    if len(PrimaryPopulation)!=len(SecondaryPopulation) or len(PrimaryPopulation)!=len(MutationPopulation):\n",
    "        return None\n",
    "    for i in range(len(AgentInputs)):\n",
    "        if PrimaryPopulation[i].GeneralScore==0 or PrimaryPopulation[i].ReasoningScore==0:\n",
    "            PrimaryPopulation[i].generateEval()\n",
    "        if SecondaryPopulation[i].GeneralScore==0 or SecondaryPopulation[i].ReasoningScore==0:\n",
    "            SecondaryPopulation[i].generateEval()\n",
    "        if MutationPopulation[i].GeneralScore==0 or MutationPopulation[i].ReasoningScore==0:\n",
    "            MutationPopulation[i].generateEval()\n",
    "\n",
    "    tasks=[]\n",
    "    PromptCrossoverCrewCopies=[PromptCrossoverCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    PromptMutationCrewCopies=[PromptMutationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=PromptCrossoverCrewCopies[i].kickoff_async(inputs={\n",
    "            'InitialTask1':PrimaryPopulation[i].RefinedPrompt,\n",
    "            'PromptCritique1':PrimaryPopulation[i].RefinedPromptCritique,\n",
    "            'InitialTask2':SecondaryPopulation[i].RefinedPrompt,\n",
    "            'PromptCritique2':SecondaryPopulation[i].RefinedPromptCritique,\n",
    "        })\n",
    "        tasks.append(task)\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=PromptMutationCrewCopies[i].kickoff_async(inputs={\n",
    "            'InitialTask':MutationPopulation[i].RefinedPrompt,\n",
    "            'PromptCritique':MutationPopulation[i].RefinedPromptCritique,\n",
    "            'ActionSteps':MutationPopulation[i].ActionSteps\n",
    "        })\n",
    "        tasks.append(task)\n",
    "    NewPrompts=await asyncio.gather(*tasks)\n",
    "    CrossoverPrompts=NewPrompts[:len(AgentInputs)] \n",
    "    MutationPrompts=NewPrompts[len(AgentInputs):]    \n",
    "    st.write(\"New Prompts Generated\")\n",
    "    \n",
    "    tasks=[]\n",
    "    InitialCritiqueCrewCopies1=[InitialCritiqueCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    InitialCritiqueCrewCopies2=[InitialCritiqueCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=InitialCritiqueCrewCopies1[i].kickoff_async(inputs={\n",
    "            'InitialTask':CrossoverPrompts[i].raw,\n",
    "            'AgentName':AgentInputs[i]['AgentName'],\n",
    "            'AgentBackstory':AgentInputs[i]['AgentBackstory'],\n",
    "            'AgentGoal':AgentInputs[i]['AgentGoal'],\n",
    "            'AgentTask':AgentInputs[i]['AgentTask']\n",
    "        })\n",
    "        tasks.append(task)\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=InitialCritiqueCrewCopies2[i].kickoff_async(inputs={\n",
    "            'InitialTask':MutationPrompts[i].raw,\n",
    "            'AgentName':AgentInputs[i]['AgentName'],\n",
    "            'AgentBackstory':AgentInputs[i]['AgentBackstory'],\n",
    "            'AgentGoal':AgentInputs[i]['AgentGoal'],\n",
    "            'AgentTask':AgentInputs[i]['AgentTask']\n",
    "        })\n",
    "        tasks.append(task)\n",
    "    UpdatedCritiques = await asyncio.gather(*tasks)\n",
    "    CrossoverCritiques=UpdatedCritiques[:len(AgentInputs)]\n",
    "    MutationCritiques=UpdatedCritiques[len(AgentInputs):]\n",
    "    st.write(\"New Critiques Generated\")\n",
    "    \n",
    "    PromptGenerator=[]\n",
    "    for i in range(len(AgentInputs)):\n",
    "        PromptGenerator.append(\n",
    "            Agents.GetCrewWithAgent(\n",
    "                Agent=get_agent(AgentInputs[i]),\n",
    "                TaskYamlFile= os.path.join(base_dir, \"definitions\", \"TaskDef\", \"SpecializedPromptGeneration.yaml\"),\n",
    "                OutputFile= os.path.join(base_dir, \"logs\", \"SpecializedPromptLogs.txt\"),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    PromptGeneratorCopies=[PromptGenerator[i].copy() for i in range(len(AgentInputs))]\n",
    "\n",
    "    tasks=[]\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=PromptGenerator[i].kickoff_async(inputs={\n",
    "            'InitialTask':CrossoverPrompts[i].raw,\n",
    "            'SpecializedGuidance':CrossoverCritiques[i].pydantic.SpecializedGuidance,\n",
    "            'SpecializedCritique':CrossoverCritiques[i].pydantic.SpecializedCritique\n",
    "        })\n",
    "        tasks.append(task)\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=PromptGeneratorCopies[i].kickoff_async(inputs={\n",
    "            'InitialTask':MutationPrompts[i].raw,\n",
    "            'SpecializedGuidance':MutationCritiques[i].pydantic.SpecializedGuidance,\n",
    "            'SpecializedCritique':MutationCritiques[i].pydantic.SpecializedCritique\n",
    "        })\n",
    "        tasks.append(task)\n",
    "    UpdatedPrompts=await asyncio.gather(*tasks)\n",
    "    CrossoverRefinedPrompts=UpdatedPrompts[:len(AgentInputs)]\n",
    "    MutationRefinedPrompts=UpdatedPrompts[len(AgentInputs):]\n",
    "    st.write(\"New Gene Prompts Generated\")\n",
    "    UpdatedPromptsRaw=[UpdatedPrompts[i].raw for i in range(len(UpdatedPrompts))]\n",
    "\n",
    "    GeneOutputs=await Agents.gather_responses(UpdatedPromptsRaw)\n",
    "    CrossoverGeneOutputs=GeneOutputs[:len(AgentInputs)]\n",
    "    MutationGeneOutputs=GeneOutputs[len(AgentInputs):]\n",
    "\n",
    "    CrossoverGenes=[]\n",
    "    MutationGenes=[]\n",
    "    for i in range(len(AgentInputs)):\n",
    "        NewGene=PromptGene(CrossoverPrompts[i].raw,CrossoverCritiques[i].pydantic.SpecializedGuidance,CrossoverCritiques[i].pydantic.SpecializedCritique,CrossoverRefinedPrompts[i].raw,CrossoverGeneOutputs[i])\n",
    "        CrossoverGenes.append(NewGene)\n",
    "    for i in range(len(AgentInputs)):\n",
    "        NewGene=PromptGene(MutationPrompts[i].raw,MutationCritiques[i].pydantic.SpecializedGuidance,MutationCritiques[i].pydantic.SpecializedCritique,MutationRefinedPrompts[i].raw,MutationGeneOutputs[i])\n",
    "        MutationGenes.append(NewGene)\n",
    "\n",
    "    PromptGeneralEvaluationCrewCopies1=[PromptGeneralEvaluationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    PromptGeneralEvaluationCrewCopies2=[PromptGeneralEvaluationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    PromptReasoningEvaluationCrewCopies1=[PromptReasoningEvaluationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    PromptReasoningEvaluationCrewCopies2=[PromptReasoningEvaluationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "\n",
    "    gen_eval_tasks=[]\n",
    "    res_eval_tasks=[]\n",
    "\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=PromptGeneralEvaluationCrewCopies1[i].kickoff_async(inputs=CrossoverGenes[i].get())\n",
    "        gen_eval_tasks.append(task)\n",
    "        task=PromptReasoningEvaluationCrewCopies1[i].kickoff_async(inputs=CrossoverGenes[i].get())\n",
    "        res_eval_tasks.append(task)\n",
    "        \n",
    "    AllTasks=gen_eval_tasks+res_eval_tasks\n",
    "    Results=await asyncio.gather(*AllTasks)\n",
    "    CrossoverGeneralScores=Results[:len(AgentInputs)]\n",
    "    CrossoverReasoningScores=Results[len(AgentInputs):]\n",
    "\n",
    "    gen_eval_tasks=[]\n",
    "    res_eval_tasks=[]\n",
    "\n",
    "    for i in range(len(AgentInputs)):\n",
    "        task=PromptGeneralEvaluationCrewCopies2[i].kickoff_async(inputs=MutationGenes[i].get())\n",
    "        gen_eval_tasks.append(task)\n",
    "        task=PromptReasoningEvaluationCrewCopies2[i].kickoff_async(inputs=MutationGenes[i].get())\n",
    "        res_eval_tasks.append(task)\n",
    "\n",
    "    AllTasks=gen_eval_tasks+res_eval_tasks\n",
    "    Results=await asyncio.gather(*AllTasks)\n",
    "    MutationGeneralScores=Results[:len(AgentInputs)]\n",
    "    MutationReasoningScores=Results[len(AgentInputs):]\n",
    "\n",
    "    PromptCritiqueEvaluationCrewCopies1=[PromptCritiqueEvaluationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "    PromptCritiqueEvaluationCrewCopies2=[PromptCritiqueEvaluationCrew.copy() for _ in range(len(AgentInputs))]\n",
    "\n",
    "    CritiqueEvalTasks=[]\n",
    "    for i in range(len(AgentInputs)):\n",
    "        inputs=CrossoverGenes[i].get()\n",
    "        task=PromptCritiqueEvaluationCrewCopies1[i].kickoff_async(inputs={\n",
    "            'InitialTask': inputs['InitialTask'],\n",
    "            'SpecializedGuidance': inputs['SpecializedGuidance'],\n",
    "            'RefinedTask': inputs['RefinedTask'],\n",
    "            'RefinedTaskOutput': inputs['RefinedTaskOutput'],\n",
    "            'GeneralEvaluation': CrossoverGeneralScores[i].raw,\n",
    "            'ReasoningEvaluation': CrossoverReasoningScores[i].raw\n",
    "        })\n",
    "        CritiqueEvalTasks.append(task)\n",
    "    for i in range(len(AgentInputs)):\n",
    "        inputs=MutationGenes[i].get()\n",
    "        task=PromptCritiqueEvaluationCrewCopies2[i].kickoff_async(inputs={\n",
    "            'InitialTask': inputs['InitialTask'],\n",
    "            'SpecializedGuidance': inputs['SpecializedGuidance'],\n",
    "            'RefinedTask': inputs['RefinedTask'],\n",
    "            'RefinedTaskOutput': inputs['RefinedTaskOutput'],\n",
    "            'GeneralEvaluation': MutationGeneralScores[i].raw,\n",
    "            'ReasoningEvaluation': MutationReasoningScores[i].raw\n",
    "        })\n",
    "        CritiqueEvalTasks.append(task)\n",
    "\n",
    "    CritiqueEvals=await asyncio.gather(*CritiqueEvalTasks)\n",
    "\n",
    "    CrossoverCritiqueEvals=CritiqueEvals[:len(AgentInputs)]\n",
    "    MutationCritiqueEvals=CritiqueEvals[len(AgentInputs):]\n",
    "\n",
    "    for i in range(len(AgentInputs)):\n",
    "        CrossoverGenes[i].GeneralScore=CrossoverGeneralScores[i].pydantic.ScoreOutof90\n",
    "        CrossoverGenes[i].ReasoningScore=CrossoverReasoningScores[i].pydantic.ScoreOutof70\n",
    "        CrossoverGenes[i].RefinedPromptCritique=CrossoverCritiqueEvals[i].pydantic.RefinedPromptCritique\n",
    "        CrossoverGenes[i].ActionSteps=CrossoverCritiqueEvals[i].pydantic.ActionableSteps\n",
    "        MutationGenes[i].GeneralScore=MutationGeneralScores[i].pydantic.ScoreOutof90\n",
    "        MutationGenes[i].ReasoningScore=MutationReasoningScores[i].pydantic.ScoreOutof70\n",
    "        MutationGenes[i].RefinedPromptCritique=MutationCritiqueEvals[i].pydantic.RefinedPromptCritique\n",
    "        MutationGenes[i].ActionSteps=MutationCritiqueEvals[i].pydantic.ActionableSteps\n",
    "        \n",
    "    return CrossoverGenes,MutationGenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "020591bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossoverPrompt(PrimaryGene, SecondaryGene):\n",
    "    if (PrimaryGene.GeneralScore==0 or PrimaryGene.ReasoningScore==0):\n",
    "        PrimaryGene.generateEval()\n",
    "    if (SecondaryGene.GeneralScore==0 or SecondaryGene.ReasoningScore==0):\n",
    "        SecondaryGene.generateEval()\n",
    "    NewPrompt=PromptCrossoverCrew.kickoff(inputs={\n",
    "        'InitialTask1':PrimaryGene.RefinedPrompt,\n",
    "        'PromptCritique1':PrimaryGene.RefinedPromptCritique,\n",
    "        'InitialTask2':SecondaryGene.RefinedPrompt,\n",
    "        'PromptCritique2':SecondaryGene.RefinedPromptCritique,\n",
    "    })\n",
    "    return NewPrompt.raw\n",
    "\n",
    "def CrossoverGene(PrimaryGene,SecondaryGene,AgentInputs):\n",
    "    NewPrompt=CrossoverPrompt(PrimaryGene,SecondaryGene)\n",
    "    print(\"New Initial Prompt Generated\")\n",
    "    print(\"Generating Crossover Gene\")\n",
    "    NewGene=GenerateGeneFromPrompt(NewPrompt,AgentInputs)\n",
    "    return NewGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "751e5188-d4f5-4e02-833b-8b34e78bf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MutatePrompt(PrimaryGene):\n",
    "    if (PrimaryGene.GeneralScore==0 or PrimaryGene.ReasoningScore==0):\n",
    "        PrimaryGene.generateEval()\n",
    "    NewPrompt=PromptMutationCrew.kickoff(inputs={\n",
    "        'InitialTask':PrimaryGene.RefinedPrompt,\n",
    "        'PromptCritique':PrimaryGene.RefinedPromptCritique,\n",
    "        'ActionSteps':PrimaryGene.ActionSteps\n",
    "    })\n",
    "    return NewPrompt.raw\n",
    "\n",
    "def MutateGene(PrimaryGene,AgentInputs):\n",
    "    NewPrompt=MutatePrompt(PrimaryGene)\n",
    "    print(\"New Initial Prompt Generated\")\n",
    "    print(\"Generating Mutated Gene\")\n",
    "    MutatedGene=GenerateGeneFromPrompt(NewPrompt,AgentInputs)\n",
    "    return MutatedGene\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2745f4df-06c3-4d8d-968e-0909cde4f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArrangePopulation(Population):\n",
    "    # Sort the population by the 'score' attribute in descending order\n",
    "    Population.sort(key=lambda obj: obj.GeneralScore+obj.ReasoningScore, reverse=True)\n",
    "    return Population   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1ccc4",
   "metadata": {},
   "source": [
    "#### Main GA Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340ca2a",
   "metadata": {},
   "source": [
    "This Part Covers the Main GA Definition for the entire workflow. Taking the following Inputs:\n",
    "- ``InitialPopulation``     : The Primary Population to be passed to GA for Optimization.\n",
    "- ``MaxGenerations``        : Defintion of the number of generations for GA to run for optimization.\n",
    "- ``MaxSelectionSize``      : Defines the Number of Genes to be present in a generation at a time, defining the termination criteria.\n",
    "- ``CrossoverRate``         : Defines the Rate of Crossover in each Generation (0-1).\n",
    "- ``MutationRate``          : Defines the Rate of Mutation in Each Generation (0-1).\n",
    "- ``LayerAgentInputs``      : Structured Input object of Dynamic Agent Selected for GA Optimization. (Corresponding the Initial Population)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1413616b-26fc-498b-a211-40dac4102792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def run_genetic_algorithm(InitialPopulation, MaxGenerations, SelectionSize, CrossoverRate,TopCarry,TopCarryRate, MutationRate, LayerAgentInputs):\n",
    "    # Initialize the population with the initial gene and a mutated version of the gene\n",
    "    population = InitialPopulation\n",
    "    \n",
    "    # Print the initial population\n",
    "    print(f\"--- Initial Population ---\")\n",
    "    print(f\"Initial Population: {population}\")\n",
    "    print(f\"Population Size: {len(population)}\\n\")\n",
    "    print(f\"Population before sorting: {population}\")\n",
    "    print(f\"Population scores before sorting: {[gene.GeneralScore+gene.ReasoningScore for gene in population]}\")\n",
    "    population = ArrangePopulation(population)\n",
    "    print(f\"Population after sorting: {population}\")\n",
    "    print(f\"Population scores after sorting: {[gene.GeneralScore+gene.ReasoningScore for gene in population]}\")\n",
    "    \n",
    "    # Begin the evolutionary loop for MaxGenerations generations\n",
    "    for generation in range(1, MaxGenerations + 1):\n",
    "        print(f\"\\n############################\")\n",
    "        print(f\"# Generation {generation}\")\n",
    "        print(f\"############################\")\n",
    "        new_population = []\n",
    "        # Step 1: Carry forward the entire population from the previous generation (Elitism)\n",
    "        print(f\"\\nStep 1: Carry forward the entire last generation's population.\")\n",
    "        print(f\"Population at start of generation {generation}: {population}\")\n",
    "        \n",
    "        # Step 2: Generate new individuals by crossover and mutation until we meet or exceed the max population size\n",
    "        print(\"\\nStep 2: Performing crossover and mutation to introduce new offspring.\")\n",
    "                \n",
    "        while True:\n",
    "            # Select two different parents for crossover\n",
    "            parent_1, parent_2 = random.sample(population, 2)  # Guarantees parent_1 != parent_2\n",
    "            print(f\"\\nSelected Parents for Crossover: Parent_1 = {parent_1}, Parent_2 = {parent_2}\")\n",
    "            \n",
    "            # Perform crossover with probability CrossoverRate\n",
    "            if random.random() < CrossoverRate:\n",
    "                print(f\"Performing Crossover (Crossover Rate: {CrossoverRate})\")\n",
    "                crossed_gene = CrossoverGene(parent_1, parent_2, LayerAgentInputs)\n",
    "                print(f\"New Crossover Gene: {crossed_gene}\")\n",
    "                new_population.append(crossed_gene)\n",
    "            else:\n",
    "                print(f\"Skipping Crossover (Crossover Rate: {CrossoverRate})\")\n",
    "\n",
    "            print(f\"\\nSelected Parents for Mutation: Parent = {population[0]}\")\n",
    "            # Step 3: Apply mutation with MutationRate probability\n",
    "            if random.random() < MutationRate:\n",
    "                print(f\"\\nMutating the Best Performing Gene (Mutation Rate: {MutationRate})\")\n",
    "                best_gene = population[0]\n",
    "                mutated_gene = MutateGene(best_gene, LayerAgentInputs)\n",
    "                new_population.append(mutated_gene)\n",
    "                print(f\"Mutated Gene: {mutated_gene}\")\n",
    "            else:\n",
    "                print(f\"Skipping Mutation (Mutation Rate: {MutationRate})\")\n",
    "\n",
    "            # Break the loop if the population has met or exceeded the MaxSelectionSize\n",
    "            if len(new_population) >= SelectionSize:\n",
    "                break  \n",
    "\n",
    "        # Step 4: Trim TopCarry individuals from the population and add them to the new population\n",
    "        print(f\"\\nStep 4: Trimming the Top {TopCarry} individuals from the population and adding them to the new population.\")\n",
    "        top_carry = population[:TopCarry]\n",
    "        print(f\"Top {TopCarry} Carry Individuals: {top_carry}\")\n",
    "        for gene in top_carry:\n",
    "            if random.random() < TopCarryRate:\n",
    "                new_population.append(gene)\n",
    "                print (f\"Adding Top Carry Individual: {gene}\")\n",
    "            else:\n",
    "                print(f\"Skipping Top Carry Individual: {gene}\")\n",
    "        print(f\"New Population after adding Top Carry Individuals: {new_population}\")\n",
    "        population = new_population\n",
    "        print(f\"New Population : {population}\")\n",
    "        # Step 5: Sort the population by fitness (best to worst) and trim to MaxSelectionSize (elitism)\n",
    "        print(f\"\\nStep 5: Sorting and trimming the population size to Top {SelectionSize}\")\n",
    "        print(f\"Population before sorting: {population}\")\n",
    "        print(f\"Population scores before sorting: {[gene.GeneralScore+gene.ReasoningScore for gene in population]}\")\n",
    "        population = ArrangePopulation(population)\n",
    "        print(f\"Population after sorting: {population}\")\n",
    "        print(f\"Population scores after sorting: {[gene.GeneralScore+gene.ReasoningScore for gene in population]}\")\n",
    "        \n",
    "        # If the population exceeds MaxSelectionSize, trim it down to the best MaxSelectionSize individuals\n",
    "        if len(population) > SelectionSize:\n",
    "            print(f\"Trimming population from {len(population)} to {SelectionSize}\")\n",
    "            population = population[:SelectionSize]    \n",
    "        print(f\"Population at the end of generation {generation}: {population}\")\n",
    "        print(f\"Population Size at the end of generation {generation}: {len(population)}\\n\")\n",
    "    \n",
    "    print(f\"\\n############################\")\n",
    "    print(f\"# Final Generation Complete\")\n",
    "    print(f\"############################\")\n",
    "    print(f\"Final population: {population}\")\n",
    "    print(f\"Final population scores: {[gene.GeneralScore+gene.ReasoningScore for gene in population]}\")\n",
    "    print(f\"Final Population Size: {len(population)}\")\n",
    "    population = ArrangePopulation(population)    \n",
    "    print(f\"\\nFinal sorted population (Top {SelectionSize}): {population}\")\n",
    "    print(f\"\\nFinal sorted population scores (Top {SelectionSize}): {[gene.GeneralScore+gene.ReasoningScore for gene in population]}\")\n",
    "    return population[:SelectionSize]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
